{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf46e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "df=pd.read_csv(\"covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81618c",
   "metadata": {},
   "source": [
    "Eseguiamo un text cleaning, emoji feature extraction, emoji semantic conversation e keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be08bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>emojis_unique</th>\n",
       "      <th>text_demojize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127412</th>\n",
       "      <td>watch live üîó: nz government to give the latest...</td>\n",
       "      <td>[üîó]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üîó]</td>\n",
       "      <td>watch live  emoji_link: nz government to give ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109812</th>\n",
       "      <td>dr scott atlas now an advisor to the wh...hopi...</td>\n",
       "      <td>[üôè, üèº]</td>\n",
       "      <td>2</td>\n",
       "      <td>[üôè, üèº]</td>\n",
       "      <td>dr scott atlas now an advisor to the wh...hopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136114</th>\n",
       "      <td>coronavirusupdates: üìçtotal covid19 cases in in...</td>\n",
       "      <td>[üìç, ‚û°]</td>\n",
       "      <td>2</td>\n",
       "      <td>[üìç, ‚û°]</td>\n",
       "      <td>coronavirusupdates:  emoji_round_pushpintotal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>bluetiful  üíô..cakesinosogbo bbnaijalockdown202...</td>\n",
       "      <td>[üíô]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üíô]</td>\n",
       "      <td>bluetiful   emoji_blue_heart..cakesinosogbo bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150279</th>\n",
       "      <td>üìπ click like follow i love ‚ù§Ô∏è you my tribe! th...</td>\n",
       "      <td>[üìπ, ‚ù§]</td>\n",
       "      <td>2</td>\n",
       "      <td>[üìπ, ‚ù§]</td>\n",
       "      <td>emoji_video_camera click like follow i love  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>covid19 impact on indiansüë∑üèΩ‚Äç‚ôÇÔ∏èmillions lost jo...</td>\n",
       "      <td>[üë∑, üèΩ, ‚ôÇ, üö∂, üè†, üß¥]</td>\n",
       "      <td>6</td>\n",
       "      <td>[üë∑, üèΩ, ‚ôÇ, üö∂, üè†, üß¥]</td>\n",
       "      <td>covid19 impact on indians emoji_man_constructi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139355</th>\n",
       "      <td>‚ú®note: dr. limengyan‚Äôs allegation of china‚Äôs c...</td>\n",
       "      <td>[‚ú®]</td>\n",
       "      <td>1</td>\n",
       "      <td>[‚ú®]</td>\n",
       "      <td>emoji_sparklesnote: dr. limengyan‚Äôs allegation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178584</th>\n",
       "      <td>hungary covid19 procurement ü§î</td>\n",
       "      <td>[ü§î]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ü§î]</td>\n",
       "      <td>hungary covid19 procurement  emoji_thinking_face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108016</th>\n",
       "      <td>be your own muse...‚ú®‚ú®üßöüèΩ‚Äç‚ôÄÔ∏ègoodmorningtwitterwo...</td>\n",
       "      <td>[‚ú®, ‚ú®, üßö, üèΩ, ‚ôÄ]</td>\n",
       "      <td>5</td>\n",
       "      <td>[‚ú®, ‚ú®, üßö, üèΩ, ‚ôÄ]</td>\n",
       "      <td>be your own muse... emoji_sparkles emoji_spark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61502</th>\n",
       "      <td>together overcome anythingüí™üíô blacklivesmatter ...</td>\n",
       "      <td>[üí™, üíô, üò∑]</td>\n",
       "      <td>3</td>\n",
       "      <td>[üí™, üíô, üò∑]</td>\n",
       "      <td>together overcome anything emoji_flexed_biceps...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean              emojis  \\\n",
       "127412  watch live üîó: nz government to give the latest...                 [üîó]   \n",
       "109812  dr scott atlas now an advisor to the wh...hopi...              [üôè, üèº]   \n",
       "136114  coronavirusupdates: üìçtotal covid19 cases in in...              [üìç, ‚û°]   \n",
       "76295   bluetiful  üíô..cakesinosogbo bbnaijalockdown202...                 [üíô]   \n",
       "150279  üìπ click like follow i love ‚ù§Ô∏è you my tribe! th...              [üìπ, ‚ù§]   \n",
       "...                                                   ...                 ...   \n",
       "4512    covid19 impact on indiansüë∑üèΩ‚Äç‚ôÇÔ∏èmillions lost jo...  [üë∑, üèΩ, ‚ôÇ, üö∂, üè†, üß¥]   \n",
       "139355  ‚ú®note: dr. limengyan‚Äôs allegation of china‚Äôs c...                 [‚ú®]   \n",
       "178584                      hungary covid19 procurement ü§î                 [ü§î]   \n",
       "108016  be your own muse...‚ú®‚ú®üßöüèΩ‚Äç‚ôÄÔ∏ègoodmorningtwitterwo...     [‚ú®, ‚ú®, üßö, üèΩ, ‚ôÄ]   \n",
       "61502   together overcome anythingüí™üíô blacklivesmatter ...           [üí™, üíô, üò∑]   \n",
       "\n",
       "        emoji_count       emojis_unique  \\\n",
       "127412            1                 [üîó]   \n",
       "109812            2              [üôè, üèº]   \n",
       "136114            2              [üìç, ‚û°]   \n",
       "76295             1                 [üíô]   \n",
       "150279            2              [üìπ, ‚ù§]   \n",
       "...             ...                 ...   \n",
       "4512              6  [üë∑, üèΩ, ‚ôÇ, üö∂, üè†, üß¥]   \n",
       "139355            1                 [‚ú®]   \n",
       "178584            1                 [ü§î]   \n",
       "108016            5     [‚ú®, ‚ú®, üßö, üèΩ, ‚ôÄ]   \n",
       "61502             3           [üí™, üíô, üò∑]   \n",
       "\n",
       "                                            text_demojize  \n",
       "127412  watch live  emoji_link: nz government to give ...  \n",
       "109812  dr scott atlas now an advisor to the wh...hopi...  \n",
       "136114  coronavirusupdates:  emoji_round_pushpintotal ...  \n",
       "76295   bluetiful   emoji_blue_heart..cakesinosogbo bb...  \n",
       "150279  emoji_video_camera click like follow i love  e...  \n",
       "...                                                   ...  \n",
       "4512    covid19 impact on indians emoji_man_constructi...  \n",
       "139355  emoji_sparklesnote: dr. limengyan‚Äôs allegation...  \n",
       "178584   hungary covid19 procurement  emoji_thinking_face  \n",
       "108016  be your own muse... emoji_sparkles emoji_spark...  \n",
       "61502   together overcome anything emoji_flexed_biceps...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text\n",
    "def clean_tweet(text):\n",
    "    text=text.lower() #lower text\n",
    "    text=re.sub(r\"https?://\\S+\",\"\",text) #remove links\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    text=re.sub(r\"@\\w+\",\"\",text) #remove mention\n",
    "    text=re.sub(r\"\\brt\\b\",\"\",text) #remove retweet\n",
    "    text=re.sub(r\"#(\\w+)\",r\"\\1\",text) # remove hashtag\n",
    "    text=re.sub(r\"[\\n\\t]\",\"\",text) # remove newline and tab\n",
    "    return text.strip()\n",
    "\n",
    "df[\"text_clean\"]=df[\"text\"].apply(clean_tweet)\n",
    "\n",
    "def has_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "df[\"emojis\"]=df[\"text_clean\"].apply(extract_emojis)\n",
    "df[\"emoji_count\"]=df[\"emojis\"].apply(len)\n",
    "df[\"has_emoji\"]=df[\"emoji_count\"]>0\n",
    "\n",
    "#Transform emoji in token\n",
    "def demojize_text(text):\n",
    "    text=emoji.demojize(text,language='en')\n",
    "    text=re.sub(r\":([a-z_]+):\",r\" emoji_\\1\",text)\n",
    "    return text.strip()\n",
    "df[\"text_demojize\"]=df[\"text_clean\"].apply(demojize_text)\n",
    "\n",
    "# List of keywords to identify COVID-19 related tweets\n",
    "covid_keywords=[\"covid\",\"covid19\",\"coronavirus\",\"sars-cov-2\",\"pandemic\"]\n",
    "\n",
    "# Function to check if a text mentions COVID-19\n",
    "def is_covid_related(text):\n",
    "    pattern = r\"\\b(\" + \"|\".join(covid_keywords) + r\")\\b\"\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "df_with_emoji=df[df[\"has_emoji\"]].copy()\n",
    "df_with_emoji=df_with_emoji[df_with_emoji[\"text_clean\"].apply(is_covid_related)].copy()\n",
    "\n",
    "def remove_duplicate_emoji(emoji_list):\n",
    "    return list(dict.fromkeys(emoji_list))\n",
    "\n",
    "\n",
    "df_with_emoji[\"emojis_unique\"]=df_with_emoji[\"emojis\"]\n",
    "\n",
    "df_with_emoji[[\"text_clean\",\"emojis\",\"emoji_count\",\"emojis_unique\",\"text_demojize\"]].sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "518a83e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_stop</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32841</th>\n",
       "      <td>[everyday, day, i, open, social, media, my, he...</td>\n",
       "      <td>[everyday, day, open, social, media, heart, ac...</td>\n",
       "      <td>[everyday, day, open, social, medium, heart, a...</td>\n",
       "      <td>everyday day open social medium heart ache see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122094</th>\n",
       "      <td>[worried, about, hospital, bills, due, to, cov...</td>\n",
       "      <td>[worried, hospital, bills, due, stay, protecte...</td>\n",
       "      <td>[worried, hospital, bill, due, stay, protected...</td>\n",
       "      <td>worried hospital bill due stay protected healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62404</th>\n",
       "      <td>[i, forgot, there, was, only, one, person, in,...</td>\n",
       "      <td>[forgot, one, person, whole, world, could, get]</td>\n",
       "      <td>[forgot, one, person, whole, world, could, get]</td>\n",
       "      <td>forgot one person whole world could get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90425</th>\n",
       "      <td>[the, american, problem, emoji_backhand_index_...</td>\n",
       "      <td>[american, problem, right, get, leadership, co...</td>\n",
       "      <td>[american, problem, right, get, leadership, co...</td>\n",
       "      <td>american problem right get leadership covidiots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120583</th>\n",
       "      <td>[emoji_fire, 10, coronavirus, scams, to, be, w...</td>\n",
       "      <td>[coronavirus, scams, wary, uk, finance, urges,...</td>\n",
       "      <td>[coronavirus, scam, wary, uk, finance, urge, p...</td>\n",
       "      <td>coronavirus scam wary uk finance urge people g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167608</th>\n",
       "      <td>[covid19, ‚Äò, scientific, ‚Äô, publications, :, o...</td>\n",
       "      <td>[scientific, publications, oops, also, see]</td>\n",
       "      <td>[scientific, publication, oops, also, see]</td>\n",
       "      <td>scientific publication oops also see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>[maharashtra, police, covid19, update, frontli...</td>\n",
       "      <td>[maharashtra, police, update, frontlineheroes,...</td>\n",
       "      <td>[maharashtra, police, update, frontlineheroes,...</td>\n",
       "      <td>maharashtra police update frontlineheroes posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136860</th>\n",
       "      <td>[clean, bold, ,, due, to, covid19, mamy, alrea...</td>\n",
       "      <td>[clean, bold, due, mamy, already, fear, n, dil...</td>\n",
       "      <td>[clean, bold, due, mamy, already, fear, n, dil...</td>\n",
       "      <td>clean bold due mamy already fear n dilem click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147748</th>\n",
       "      <td>[here, 's, your, solution, :, oncoming_fist_me...</td>\n",
       "      <td>[solution, bybyfitness, schoolsreopening, bbna...</td>\n",
       "      <td>[solution, bybyfitness, schoolsreopening, bbna...</td>\n",
       "      <td>solution bybyfitness schoolsreopening bbnaija ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66817</th>\n",
       "      <td>[covid19, be, a, good, start, so.u.k, ., start...</td>\n",
       "      <td>[good, start, starting, look, like, one, world...</td>\n",
       "      <td>[good, start, start, look, like, one, world, b...</td>\n",
       "      <td>good start start look like one world big problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  \\\n",
       "32841   [everyday, day, i, open, social, media, my, he...   \n",
       "122094  [worried, about, hospital, bills, due, to, cov...   \n",
       "62404   [i, forgot, there, was, only, one, person, in,...   \n",
       "90425   [the, american, problem, emoji_backhand_index_...   \n",
       "120583  [emoji_fire, 10, coronavirus, scams, to, be, w...   \n",
       "167608  [covid19, ‚Äò, scientific, ‚Äô, publications, :, o...   \n",
       "1051    [maharashtra, police, covid19, update, frontli...   \n",
       "136860  [clean, bold, ,, due, to, covid19, mamy, alrea...   \n",
       "147748  [here, 's, your, solution, :, oncoming_fist_me...   \n",
       "66817   [covid19, be, a, good, start, so.u.k, ., start...   \n",
       "\n",
       "                                           tokens_no_stop  \\\n",
       "32841   [everyday, day, open, social, media, heart, ac...   \n",
       "122094  [worried, hospital, bills, due, stay, protecte...   \n",
       "62404     [forgot, one, person, whole, world, could, get]   \n",
       "90425   [american, problem, right, get, leadership, co...   \n",
       "120583  [coronavirus, scams, wary, uk, finance, urges,...   \n",
       "167608        [scientific, publications, oops, also, see]   \n",
       "1051    [maharashtra, police, update, frontlineheroes,...   \n",
       "136860  [clean, bold, due, mamy, already, fear, n, dil...   \n",
       "147748  [solution, bybyfitness, schoolsreopening, bbna...   \n",
       "66817   [good, start, starting, look, like, one, world...   \n",
       "\n",
       "                                             final_tokens  \\\n",
       "32841   [everyday, day, open, social, medium, heart, a...   \n",
       "122094  [worried, hospital, bill, due, stay, protected...   \n",
       "62404     [forgot, one, person, whole, world, could, get]   \n",
       "90425   [american, problem, right, get, leadership, co...   \n",
       "120583  [coronavirus, scam, wary, uk, finance, urge, p...   \n",
       "167608         [scientific, publication, oops, also, see]   \n",
       "1051    [maharashtra, police, update, frontlineheroes,...   \n",
       "136860  [clean, bold, due, mamy, already, fear, n, dil...   \n",
       "147748  [solution, bybyfitness, schoolsreopening, bbna...   \n",
       "66817   [good, start, start, look, like, one, world, b...   \n",
       "\n",
       "                                               final_text  \n",
       "32841   everyday day open social medium heart ache see...  \n",
       "122094  worried hospital bill due stay protected healt...  \n",
       "62404             forgot one person whole world could get  \n",
       "90425     american problem right get leadership covidiots  \n",
       "120583  coronavirus scam wary uk finance urge people g...  \n",
       "167608               scientific publication oops also see  \n",
       "1051    maharashtra police update frontlineheroes posi...  \n",
       "136860  clean bold due mamy already fear n dilem click...  \n",
       "147748  solution bybyfitness schoolsreopening bbnaija ...  \n",
       "66817    good start start look like one world big problem  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "#Tokenize text using NLTK\n",
    "df_with_emoji[\"tokens\"]=df_with_emoji[\"text_demojize\"].apply(word_tokenize)\n",
    "\n",
    "#Remove Stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    #Remove english and non-alphabetic tokens\n",
    "    return [word for word in tokens if word.isalpha() and word not in stopwords]\n",
    "df_with_emoji[\"tokens_no_stop\"]=df_with_emoji[\"tokens\"].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "#Lemmantization\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "#Function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'): \n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'): \n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN #Default\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    if not isinstance(tokens,list) or len(tokens) ==0:\n",
    "        return []\n",
    "    tagged_tokens=pos_tag(tokens)\n",
    "    return [lemmatizer.lemmatize(word,get_wordnet_pos(pos)) for word,pos in tagged_tokens]\n",
    "\n",
    "df_with_emoji[\"final_tokens\"]=df_with_emoji[\"tokens_no_stop\"].apply(lemmatize_tokens)\n",
    "\n",
    "df_with_emoji[\"final_text\"]=df_with_emoji[\"final_tokens\"].apply(lambda x: \" \".join(x))\n",
    "df_with_emoji[[\"tokens\",\"tokens_no_stop\",\"final_tokens\",\"final_text\"]].sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe3a2ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9073, 11109)\n",
      "<bound method CountVectorizer.get_feature_names_out of CountVectorizer()>\n"
     ]
    }
   ],
   "source": [
    "#Create Bag of Words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorize=CountVectorizer()\n",
    "\n",
    "X=vectorize.fit_transform(df_with_emoji[\"final_text\"])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(vectorize.get_feature_names_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40be36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 0.63\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.22      0.35       386\n",
      "     Neutral       0.77      0.50      0.61       632\n",
      "    Positive       0.57      0.94      0.71       797\n",
      "\n",
      "    accuracy                           0.63      1815\n",
      "   macro avg       0.75      0.55      0.56      1815\n",
      "weighted avg       0.71      0.63      0.60      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB,MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "#We generate labels using VADER (Automatically handles emohis)\n",
    "def label_sentiment(text):\n",
    "   score=analyzer.polarity_scores(text)['compound']\n",
    "   if score>0.05:\n",
    "      return \"Positive\"\n",
    "   elif score<=-0.05:\n",
    "      return \"Negative\"\n",
    "   else:\n",
    "      return \"Neutral\"\n",
    "   \n",
    "df_with_emoji[\"sentiment\"]=df_with_emoji[\"text_clean\"].apply(label_sentiment)\n",
    "\n",
    "X=df_with_emoji[\"text_demojize\"]\n",
    "y=df_with_emoji[\"sentiment\"] #Target labels\n",
    "\n",
    "#Training\n",
    "X_train_raw,X_test_raw,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#TF-IDF\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2),token_pattern=r\"\\b\\w\\w+\\b\",stop_words=\"english\")\n",
    "\n",
    "#Fit on training data and transform both sets into numerical matrices\n",
    "X_train_tfidf=tfidf.fit_transform(X_train_raw)\n",
    "X_test_tfidf=tfidf.transform(X_test_raw)\n",
    "\n",
    "#Initializing and training Complement Naive Bayes Classifier\n",
    "model=MultinomialNB()\n",
    "model.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#Model evaluation\n",
    "y_pred=model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Global Accuracy: {accuracy_score(y_test,y_pred):.2f}\\n\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
