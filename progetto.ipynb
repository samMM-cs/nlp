{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf46e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "df=pd.read_csv(\"covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be08bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>emojis_unique</th>\n",
       "      <th>text_demojize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138806</th>\n",
       "      <td>ğŸ™ğŸ•¯ğŸ™thoughtsandprayers for his loved ones.covid...</td>\n",
       "      <td>[ğŸ™, ğŸ•¯, ğŸ™]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ğŸ™, ğŸ•¯]</td>\n",
       "      <td>emoji_folded_hands emoji_candle emoji_folded_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137663</th>\n",
       "      <td>just did an interview where they record your a...</td>\n",
       "      <td>[ğŸ¥µ, ğŸ¤, ğŸ˜©]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ğŸ¥µ, ğŸ¤, ğŸ˜©]</td>\n",
       "      <td>just did an interview where they record your a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163917</th>\n",
       "      <td>ğŸ’®ğŸš¢ğŸš¢ğŸš¢ğŸš¢ ğŸ¤”four cargo ships off queensland may hav...</td>\n",
       "      <td>[ğŸ’®, ğŸš¢, ğŸš¢, ğŸš¢, ğŸš¢, ğŸ¤”]</td>\n",
       "      <td>6</td>\n",
       "      <td>[ğŸ’®, ğŸš¢, ğŸ¤”]</td>\n",
       "      <td>emoji_white_flower emoji_ship emoji_ship emoji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33565</th>\n",
       "      <td>after this corona pandemic we need to be added...</td>\n",
       "      <td>[ğŸ¥º]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ğŸ¥º]</td>\n",
       "      <td>after this corona pandemic we need to be added...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158332</th>\n",
       "      <td>ğŸ“» weâ€™ve been working with  and radio stations ...</td>\n",
       "      <td>[ğŸ“», ğŸ‘‚, ğŸ¾]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ğŸ“», ğŸ‘‚, ğŸ¾]</td>\n",
       "      <td>emoji_radio weâ€™ve been working with  and radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125424</th>\n",
       "      <td>covid19 update. on august 14 as of 11:00 in ar...</td>\n",
       "      <td>[âœ…, âœ…]</td>\n",
       "      <td>2</td>\n",
       "      <td>[âœ…]</td>\n",
       "      <td>covid19 update. on august 14 as of 11:00 in ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>justice baker for deputy ag.ğŸ‘ğŸ‘police protectth...</td>\n",
       "      <td>[ğŸ‘, ğŸ‘]</td>\n",
       "      <td>2</td>\n",
       "      <td>[ğŸ‘, ğŸ‘]</td>\n",
       "      <td>justice baker for deputy ag. emoji_thumbs_up e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148908</th>\n",
       "      <td>ğŸ–‹ sign â€œauthorize covid-19 rapid testingâ€ and ...</td>\n",
       "      <td>[ğŸ–‹, ğŸ“¨]</td>\n",
       "      <td>2</td>\n",
       "      <td>[ğŸ–‹, ğŸ“¨]</td>\n",
       "      <td>emoji_fountain_pen sign â€œauthorize covid-19 ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101091</th>\n",
       "      <td>honourable  shri  sir please ğŸ™ give us subsidy...</td>\n",
       "      <td>[ğŸ™]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ğŸ™]</td>\n",
       "      <td>honourable  shri  sir please  emoji_folded_han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31493</th>\n",
       "      <td>in covid19 ğŸ˜·pandemictrust me the computer coul...</td>\n",
       "      <td>[ğŸ˜·]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ğŸ˜·]</td>\n",
       "      <td>in covid19  emoji_face_with_medical_maskpandem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean              emojis  \\\n",
       "138806  ğŸ™ğŸ•¯ğŸ™thoughtsandprayers for his loved ones.covid...           [ğŸ™, ğŸ•¯, ğŸ™]   \n",
       "137663  just did an interview where they record your a...           [ğŸ¥µ, ğŸ¤, ğŸ˜©]   \n",
       "163917  ğŸ’®ğŸš¢ğŸš¢ğŸš¢ğŸš¢ ğŸ¤”four cargo ships off queensland may hav...  [ğŸ’®, ğŸš¢, ğŸš¢, ğŸš¢, ğŸš¢, ğŸ¤”]   \n",
       "33565   after this corona pandemic we need to be added...                 [ğŸ¥º]   \n",
       "158332  ğŸ“» weâ€™ve been working with  and radio stations ...           [ğŸ“», ğŸ‘‚, ğŸ¾]   \n",
       "...                                                   ...                 ...   \n",
       "125424  covid19 update. on august 14 as of 11:00 in ar...              [âœ…, âœ…]   \n",
       "155698  justice baker for deputy ag.ğŸ‘ğŸ‘police protectth...              [ğŸ‘, ğŸ‘]   \n",
       "148908  ğŸ–‹ sign â€œauthorize covid-19 rapid testingâ€ and ...              [ğŸ–‹, ğŸ“¨]   \n",
       "101091  honourable  shri  sir please ğŸ™ give us subsidy...                 [ğŸ™]   \n",
       "31493   in covid19 ğŸ˜·pandemictrust me the computer coul...                 [ğŸ˜·]   \n",
       "\n",
       "        emoji_count emojis_unique  \\\n",
       "138806            3        [ğŸ™, ğŸ•¯]   \n",
       "137663            3     [ğŸ¥µ, ğŸ¤, ğŸ˜©]   \n",
       "163917            6     [ğŸ’®, ğŸš¢, ğŸ¤”]   \n",
       "33565             1           [ğŸ¥º]   \n",
       "158332            3     [ğŸ“», ğŸ‘‚, ğŸ¾]   \n",
       "...             ...           ...   \n",
       "125424            2           [âœ…]   \n",
       "155698            2        [ğŸ‘, ğŸ‘]   \n",
       "148908            2        [ğŸ–‹, ğŸ“¨]   \n",
       "101091            1           [ğŸ™]   \n",
       "31493             1           [ğŸ˜·]   \n",
       "\n",
       "                                            text_demojize  \n",
       "138806  emoji_folded_hands emoji_candle emoji_folded_h...  \n",
       "137663  just did an interview where they record your a...  \n",
       "163917  emoji_white_flower emoji_ship emoji_ship emoji...  \n",
       "33565   after this corona pandemic we need to be added...  \n",
       "158332  emoji_radio weâ€™ve been working with  and radio...  \n",
       "...                                                   ...  \n",
       "125424  covid19 update. on august 14 as of 11:00 in ar...  \n",
       "155698  justice baker for deputy ag. emoji_thumbs_up e...  \n",
       "148908  emoji_fountain_pen sign â€œauthorize covid-19 ra...  \n",
       "101091  honourable  shri  sir please  emoji_folded_han...  \n",
       "31493   in covid19  emoji_face_with_medical_maskpandem...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text\n",
    "def clean_tweet(text):\n",
    "    text=text.lower() #lower text\n",
    "    text=re.sub(r\"https?://\\S+\",\"\",text) #remove links\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    text=re.sub(r\"@\\w+\",\"\",text) #remove mention\n",
    "    text=re.sub(r\"\\brt\\b\",\"\",text) #remove retweet\n",
    "    text=re.sub(r\"#(\\w+)\",r\"\\1\",text) # remove hashtag\n",
    "    text=re.sub(r\"[\\n\\t]\",\"\",text) # remove newline and tab\n",
    "    return text.strip()\n",
    "\n",
    "df[\"text_clean\"]=df[\"text\"].apply(clean_tweet)\n",
    "\n",
    "def has_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "df[\"emojis\"]=df[\"text_clean\"].apply(extract_emojis)\n",
    "df[\"emoji_count\"]=df[\"emojis\"].apply(len)\n",
    "df[\"has_emoji\"]=df[\"emoji_count\"]>0\n",
    "\n",
    "#Transform emoji in token\n",
    "def demojize_text(text):\n",
    "    text=emoji.demojize(text)\n",
    "    text=re.sub(r\":([a-z_]+):\",r\" emoji_\\1\",text)\n",
    "    return text.strip()\n",
    "df[\"text_demojize\"]=df[\"text_clean\"].apply(demojize_text)\n",
    "\n",
    "# List of keywords to identify COVID-19 related tweets\n",
    "covid_keywords=[\"covid\",\"covid19\",\"coronavirus\",\"sars-cov-2\",\"pandemic\"]\n",
    "\n",
    "# Function to check if a text mentions COVID-19\n",
    "def is_covid_related(text):\n",
    "    pattern = r\"\\b(\" + \"|\".join(covid_keywords) + r\")\\b\"\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "df_with_emoji=df[df[\"has_emoji\"]].copy()\n",
    "df_with_emoji=df_with_emoji[df_with_emoji[\"text_clean\"].apply(is_covid_related)].copy()\n",
    "\n",
    "def remove_duplicate_emoji(emoji_list):\n",
    "    return list(dict.fromkeys(emoji_list))\n",
    "\n",
    "\n",
    "df_with_emoji[\"emojis_unique\"]=df_with_emoji[\"emojis\"].apply(remove_duplicate_emoji)\n",
    "\n",
    "df_with_emoji[[\"text_clean\",\"emojis\",\"emoji_count\",\"emojis_unique\",\"text_demojize\"]].sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40be36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 0.71\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.63      0.67       386\n",
      "     Neutral       0.73      0.58      0.65       632\n",
      "    Positive       0.69      0.84      0.76       797\n",
      "\n",
      "    accuracy                           0.71      1815\n",
      "   macro avg       0.71      0.69      0.69      1815\n",
      "weighted avg       0.71      0.71      0.70      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "#We generate labels using VADER (Automatically handles emohis)\n",
    "def label_sentiment(text):\n",
    "   score=analyzer.polarity_scores(text)['compound']\n",
    "   if score>0.05:\n",
    "      return \"Positive\"\n",
    "   elif score<=-0.05:\n",
    "      return \"Negative\"\n",
    "   else:\n",
    "      return \"Neutral\"\n",
    "   \n",
    "df_with_emoji[\"sentiment\"]=df_with_emoji[\"text_clean\"].apply(label_sentiment)\n",
    "\n",
    "df_with_emoji[[\"text_clean\",\"emojis\",\"emoji_count\",\"emojis_unique\",\"text_demojize\",\"sentiment\"]].sample(1000)\n",
    "\n",
    "X=df_with_emoji[\"text_demojize\"] #Feature (text containing emoji tokens like 'emoji_face_mask')\n",
    "y=df_with_emoji[\"sentiment\"] #Target labels\n",
    "\n",
    "#Training\n",
    "X_train_raw,X_test_raw,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#TF-IDF\n",
    "tfidf=TfidfVectorizer(token_pattern=r\"\\b\\w\\w+\\b|emoji_\\w+\",stop_words=\"english\")\n",
    "\n",
    "#Fit on training data and transform both sets into numerical matrices\n",
    "X_train_tfidf=tfidf.fit_transform(X_train_raw)\n",
    "X_test_tfidf=tfidf.transform(X_test_raw)\n",
    "\n",
    "#Initializing and training Multinomial Naive Bayes Classifier\n",
    "model=ComplementNB() #Per i dataset sbilanciati\n",
    "model.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#Model evaluation\n",
    "y_pred=model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Global Accuracy: {accuracy_score(y_test,y_pred):.2f}\\n\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
