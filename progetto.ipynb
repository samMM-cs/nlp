{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf46e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81618c",
   "metadata": {},
   "source": [
    "Eseguiamo un text cleaning, emoji feature extraction, emoji semantic conversation e keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7be08bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>emojis_unique</th>\n",
       "      <th>text_demojize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41676</th>\n",
       "      <td>covid19 ü¶† - sdmc 29-7-2020 üö® üö® postponing on t...</td>\n",
       "      <td>[ü¶†, üö®, üö®]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ü¶†, üö®, üö®]</td>\n",
       "      <td>covid19  emoji_microbe - sdmc 29-7-2020  emoji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33095</th>\n",
       "      <td>‡¥Ü‡¥∂‡¥ô‡µç‡¥ï ‡¥ï‡µÅ‡¥±‡¥Ø‡¥æ‡¥§‡µÜ ‡¥§‡¥µ‡¥ø‡¥û‡µç‡¥û‡¥æ‡¥≤‡µç‚Äç | thavinjal covid 19c...</td>\n",
       "      <td>[üëâ]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üëâ]</td>\n",
       "      <td>‡¥Ü‡¥∂‡¥ô‡µç‡¥ï ‡¥ï‡µÅ‡¥±‡¥Ø‡¥æ‡¥§‡µÜ ‡¥§‡¥µ‡¥ø‡¥û‡µç‡¥û‡¥æ‡¥≤‡µç‚Äç | thavinjal covid 19c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9218</th>\n",
       "      <td>indiafightscorona:üìçpreventive measures in rest...</td>\n",
       "      <td>[üìç, ‚ñ∂, ‚ñ∂]</td>\n",
       "      <td>3</td>\n",
       "      <td>[üìç, ‚ñ∂, ‚ñ∂]</td>\n",
       "      <td>indiafightscorona: emoji_round_pushpinpreventi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89824</th>\n",
       "      <td>coronavirusupdate7-8-2020 23:59 utctotal covid...</td>\n",
       "      <td>[‚¨á, ‚Üî]</td>\n",
       "      <td>2</td>\n",
       "      <td>[‚¨á, ‚Üî]</td>\n",
       "      <td>coronavirusupdate7-8-2020 23:59 utctotal covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173285</th>\n",
       "      <td>level2 covid19 nz jacindaardern level 2.5: cov...</td>\n",
       "      <td>[‚ú®, ü•∞, üßö, ‚ôÄ]</td>\n",
       "      <td>4</td>\n",
       "      <td>[‚ú®, ü•∞, üßö, ‚ôÄ]</td>\n",
       "      <td>level2 covid19 nz jacindaardern level 2.5: cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168411</th>\n",
       "      <td>cross fingers, perhaps soon we won't need to s...</td>\n",
       "      <td>[üòä]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üòä]</td>\n",
       "      <td>cross fingers, perhaps soon we won't need to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94779</th>\n",
       "      <td>we are at snec expo, shanghai now! come hug us...</td>\n",
       "      <td>[üòò]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üòò]</td>\n",
       "      <td>we are at snec expo, shanghai now! come hug us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58146</th>\n",
       "      <td>covid19 and its subsequent health and economic...</td>\n",
       "      <td>[üìâ, ü•¶]</td>\n",
       "      <td>2</td>\n",
       "      <td>[üìâ, ü•¶]</td>\n",
       "      <td>covid19 and its subsequent health and economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40033</th>\n",
       "      <td>allahdoesnotneedqurbani cmomaharashtra maharas...</td>\n",
       "      <td>[üí•]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üí•]</td>\n",
       "      <td>allahdoesnotneedqurbani cmomaharashtra maharas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110238</th>\n",
       "      <td>that's a great idea marieüëçnhs uhb covid19</td>\n",
       "      <td>[üëç]</td>\n",
       "      <td>1</td>\n",
       "      <td>[üëç]</td>\n",
       "      <td>that's a great idea marie emoji_thumbs_upnhs u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean        emojis  \\\n",
       "41676   covid19 ü¶† - sdmc 29-7-2020 üö® üö® postponing on t...     [ü¶†, üö®, üö®]   \n",
       "33095   ‡¥Ü‡¥∂‡¥ô‡µç‡¥ï ‡¥ï‡µÅ‡¥±‡¥Ø‡¥æ‡¥§‡µÜ ‡¥§‡¥µ‡¥ø‡¥û‡µç‡¥û‡¥æ‡¥≤‡µç‚Äç | thavinjal covid 19c...           [üëâ]   \n",
       "9218    indiafightscorona:üìçpreventive measures in rest...     [üìç, ‚ñ∂, ‚ñ∂]   \n",
       "89824   coronavirusupdate7-8-2020 23:59 utctotal covid...        [‚¨á, ‚Üî]   \n",
       "173285  level2 covid19 nz jacindaardern level 2.5: cov...  [‚ú®, ü•∞, üßö, ‚ôÄ]   \n",
       "...                                                   ...           ...   \n",
       "168411  cross fingers, perhaps soon we won't need to s...           [üòä]   \n",
       "94779   we are at snec expo, shanghai now! come hug us...           [üòò]   \n",
       "58146   covid19 and its subsequent health and economic...        [üìâ, ü•¶]   \n",
       "40033   allahdoesnotneedqurbani cmomaharashtra maharas...           [üí•]   \n",
       "110238          that's a great idea marieüëçnhs uhb covid19           [üëç]   \n",
       "\n",
       "        emoji_count emojis_unique  \\\n",
       "41676             3     [ü¶†, üö®, üö®]   \n",
       "33095             1           [üëâ]   \n",
       "9218              3     [üìç, ‚ñ∂, ‚ñ∂]   \n",
       "89824             2        [‚¨á, ‚Üî]   \n",
       "173285            4  [‚ú®, ü•∞, üßö, ‚ôÄ]   \n",
       "...             ...           ...   \n",
       "168411            1           [üòä]   \n",
       "94779             1           [üòò]   \n",
       "58146             2        [üìâ, ü•¶]   \n",
       "40033             1           [üí•]   \n",
       "110238            1           [üëç]   \n",
       "\n",
       "                                            text_demojize  \n",
       "41676   covid19  emoji_microbe - sdmc 29-7-2020  emoji...  \n",
       "33095   ‡¥Ü‡¥∂‡¥ô‡µç‡¥ï ‡¥ï‡µÅ‡¥±‡¥Ø‡¥æ‡¥§‡µÜ ‡¥§‡¥µ‡¥ø‡¥û‡µç‡¥û‡¥æ‡¥≤‡µç‚Äç | thavinjal covid 19c...  \n",
       "9218    indiafightscorona: emoji_round_pushpinpreventi...  \n",
       "89824   coronavirusupdate7-8-2020 23:59 utctotal covid...  \n",
       "173285  level2 covid19 nz jacindaardern level 2.5: cov...  \n",
       "...                                                   ...  \n",
       "168411  cross fingers, perhaps soon we won't need to s...  \n",
       "94779   we are at snec expo, shanghai now! come hug us...  \n",
       "58146   covid19 and its subsequent health and economic...  \n",
       "40033   allahdoesnotneedqurbani cmomaharashtra maharas...  \n",
       "110238  that's a great idea marie emoji_thumbs_upnhs u...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text\n",
    "def clean_tweet(text):\n",
    "    text=text.lower() #lower text\n",
    "    text=re.sub(r\"https?://\\S+\",\"\",text) #remove links\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    text=re.sub(r\"@\\w+\",\"\",text) #remove mention\n",
    "    text=re.sub(r\"\\brt\\b\",\"\",text) #remove retweet\n",
    "    text=re.sub(r\"#(\\w+)\",r\"\\1\",text) # remove hashtag\n",
    "    text=re.sub(r\"[\\n\\t]\",\"\",text) # remove newline and tab\n",
    "    return text.strip()\n",
    "\n",
    "df[\"text_clean\"]=df[\"text\"].apply(clean_tweet)\n",
    "\n",
    "def has_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "df[\"emojis\"]=df[\"text_clean\"].apply(extract_emojis)\n",
    "df[\"emoji_count\"]=df[\"emojis\"].apply(len)\n",
    "df[\"has_emoji\"]=df[\"emoji_count\"]>0\n",
    "\n",
    "#Transform emoji in token\n",
    "def demojize_text(text):\n",
    "    text=emoji.demojize(text,language='en')\n",
    "    text=re.sub(r\":([a-z_]+):\",r\" emoji_\\1\",text)\n",
    "    return text.strip()\n",
    "df[\"text_demojize\"]=df[\"text_clean\"].apply(demojize_text)\n",
    "\n",
    "# List of keywords to identify COVID-19 related tweets\n",
    "covid_keywords=[\"covid\",\"covid19\",\"coronavirus\",\"sars-cov-2\",\"pandemic\"]\n",
    "\n",
    "# Function to check if a text mentions COVID-19\n",
    "def is_covid_related(text):\n",
    "    pattern = r\"\\b(\" + \"|\".join(covid_keywords) + r\")\\b\"\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "df_with_emoji=df[df[\"has_emoji\"]].copy()\n",
    "df_with_emoji=df_with_emoji[df_with_emoji[\"text_clean\"].apply(is_covid_related)].copy()\n",
    "\n",
    "def remove_duplicate_emoji(emoji_list):\n",
    "    return list(dict.fromkeys(emoji_list))\n",
    "\n",
    "\n",
    "df_with_emoji[\"emojis_unique\"]=df_with_emoji[\"emojis\"]\n",
    "\n",
    "df_with_emoji[[\"text_clean\",\"emojis\",\"emoji_count\",\"emojis_unique\",\"text_demojize\"]].sample(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "518a83e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_demojize</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171109</th>\n",
       "      <td>more dumbasses.  emoji_woman_facepalming_light...</td>\n",
       "      <td>[more, dumbass, ., emoji_woman_facepalming_lig...</td>\n",
       "      <td>more dumbass . emoji_woman_facepalming_light_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71478</th>\n",
       "      <td>coronavirusupdates: covid19 india tracker(as o...</td>\n",
       "      <td>[coronavirusupdates, :, covid19, india, tracke...</td>\n",
       "      <td>coronavirusupdates : covid19 india tracker ( a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>emoji_airplane learn more about iata's safety ...</td>\n",
       "      <td>[emoji_airplane, learn, more, about, iata, 's,...</td>\n",
       "      <td>emoji_airplane learn more about iata 's safety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>covid19 tenders. niggas bought bmw stock out. ...</td>\n",
       "      <td>[covid19, tender, ., nigga, buy, bmw, stock, o...</td>\n",
       "      <td>covid19 tender . nigga buy bmw stock out . emo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59175</th>\n",
       "      <td>love should tule the world  emoji_red_heart em...</td>\n",
       "      <td>[love, should, tule, the, world, emoji_red_hea...</td>\n",
       "      <td>love should tule the world emoji_red_heart emo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13330</th>\n",
       "      <td>kids wouldn‚Äôt pose with us with masks!  emoji_...</td>\n",
       "      <td>[kid, wouldn, ‚Äô, t, pose, with, u, with, mask,...</td>\n",
       "      <td>kid wouldn ‚Äô t pose with u with mask ! emoji_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146777</th>\n",
       "      <td>no covid19 didn‚Äôt infect climatechange it‚Äôs st...</td>\n",
       "      <td>[no, covid19, didn, ‚Äô, t, infect, climatechang...</td>\n",
       "      <td>no covid19 didn ‚Äô t infect climatechange it ‚Äô ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>please don't view n pass... patronize me abeg ...</td>\n",
       "      <td>[please, do, n't, view, n, pas, ..., patronize...</td>\n",
       "      <td>please do n't view n pas ... patronize me abeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92558</th>\n",
       "      <td>amitshah to chinese virus, covid19  emoji_smil...</td>\n",
       "      <td>[amitshah, to, chinese, virus, ,, covid19, emo...</td>\n",
       "      <td>amitshah to chinese virus , covid19 emoji_smil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101288</th>\n",
       "      <td>the latest the force for health emoji_register...</td>\n",
       "      <td>[the, late, the, force, for, health, emoji_reg...</td>\n",
       "      <td>the late the force for health emoji_registered...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_demojize  \\\n",
       "171109  more dumbasses.  emoji_woman_facepalming_light...   \n",
       "71478   coronavirusupdates: covid19 india tracker(as o...   \n",
       "4214    emoji_airplane learn more about iata's safety ...   \n",
       "11687   covid19 tenders. niggas bought bmw stock out. ...   \n",
       "59175   love should tule the world  emoji_red_heart em...   \n",
       "13330   kids wouldn‚Äôt pose with us with masks!  emoji_...   \n",
       "146777  no covid19 didn‚Äôt infect climatechange it‚Äôs st...   \n",
       "4007    please don't view n pass... patronize me abeg ...   \n",
       "92558   amitshah to chinese virus, covid19  emoji_smil...   \n",
       "101288  the latest the force for health emoji_register...   \n",
       "\n",
       "                                             final_tokens  \\\n",
       "171109  [more, dumbass, ., emoji_woman_facepalming_lig...   \n",
       "71478   [coronavirusupdates, :, covid19, india, tracke...   \n",
       "4214    [emoji_airplane, learn, more, about, iata, 's,...   \n",
       "11687   [covid19, tender, ., nigga, buy, bmw, stock, o...   \n",
       "59175   [love, should, tule, the, world, emoji_red_hea...   \n",
       "13330   [kid, wouldn, ‚Äô, t, pose, with, u, with, mask,...   \n",
       "146777  [no, covid19, didn, ‚Äô, t, infect, climatechang...   \n",
       "4007    [please, do, n't, view, n, pas, ..., patronize...   \n",
       "92558   [amitshah, to, chinese, virus, ,, covid19, emo...   \n",
       "101288  [the, late, the, force, for, health, emoji_reg...   \n",
       "\n",
       "                                               final_text  \n",
       "171109  more dumbass . emoji_woman_facepalming_light_s...  \n",
       "71478   coronavirusupdates : covid19 india tracker ( a...  \n",
       "4214    emoji_airplane learn more about iata 's safety...  \n",
       "11687   covid19 tender . nigga buy bmw stock out . emo...  \n",
       "59175   love should tule the world emoji_red_heart emo...  \n",
       "13330   kid wouldn ‚Äô t pose with u with mask ! emoji_f...  \n",
       "146777  no covid19 didn ‚Äô t infect climatechange it ‚Äô ...  \n",
       "4007    please do n't view n pas ... patronize me abeg...  \n",
       "92558   amitshah to chinese virus , covid19 emoji_smil...  \n",
       "101288  the late the force for health emoji_registered...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "#Tokenize text using NLTK\n",
    "df_with_emoji[\"tokens\"]=df_with_emoji[\"text_demojize\"].apply(word_tokenize)\n",
    "\n",
    "#Remove Stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "#Lemmantization\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "#Function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'): \n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'): \n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN #Default\n",
    "\n",
    "def lemmatize_tokens(text):\n",
    "    tokens=word_tokenize(text.lower())\n",
    "    tagged_tokens=pos_tag(tokens)\n",
    "    final=[]\n",
    "    for word, tag in tagged_tokens:\n",
    "        if(word.isalpha() or word.startswith(':') and word not in stopwords):\n",
    "            final.append(lemmatizer.lemmatize(word,get_wordnet_pos(tag)))\n",
    "\n",
    "    return [lemmatizer.lemmatize(word,get_wordnet_pos(pos)) for word,pos in tagged_tokens]\n",
    "\n",
    "df_with_emoji[\"final_tokens\"]=df_with_emoji[\"text_demojize\"].apply(lemmatize_tokens)\n",
    "\n",
    "df_with_emoji[\"final_text\"]=df_with_emoji[\"final_tokens\"].apply(lambda x: \" \".join(x))\n",
    "df_with_emoji[[\"text_demojize\",\"final_tokens\",\"final_text\",]].sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40be36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 0.88\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.73      0.80       383\n",
      "    Positive       0.88      0.95      0.92       810\n",
      "\n",
      "    accuracy                           0.88      1193\n",
      "   macro avg       0.88      0.84      0.86      1193\n",
      "weighted avg       0.88      0.88      0.88      1193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB,MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "#We generate labels using VADER (Automatically handles emojis)\n",
    "def label_sentiment(text):\n",
    "   score=analyzer.polarity_scores(text)['compound']\n",
    "   if score>0.05:\n",
    "      return \"Positive\"\n",
    "   elif score<=-0.05:\n",
    "      return \"Negative\"\n",
    "   else:\n",
    "      return \"Neutral\"\n",
    "\n",
    "df_with_emoji[\"sentiment\"]=df_with_emoji[\"text_clean\"].apply(label_sentiment)\n",
    "df_with_emoji=df_with_emoji[df_with_emoji[\"sentiment\"] != \"Neutral\"].copy()\n",
    "\n",
    "df_with_emoji[\"vader_compound\"]=df_with_emoji[\"text_clean\"].apply(lambda t: analyzer.polarity_scores(t)['compound'])\n",
    "\n",
    "def emoji_score(text):\n",
    "   #Estraggo le emoji dal testo\n",
    "   emoji_found=[c for c in text if c in emoji.EMOJI_DATA]\n",
    "   if not emoji_found:\n",
    "      return 0\n",
    "   \n",
    "   score=sum(analyzer.polarity_scores(e)['compound'] for e in emoji_found)\n",
    "   return np.tanh(score) #Per 'schiacciare il valore'\n",
    "\n",
    "df_with_emoji[\"emoji_score\"]=df_with_emoji[\"text_clean\"].apply(emoji_score)\n",
    "\n",
    "X_text=df_with_emoji[\"final_text\"]\n",
    "X_extra=df_with_emoji[[\"vader_compound\",\"emoji_score\"]]\n",
    "y=df_with_emoji[\"sentiment\"] #Target labels\n",
    "\n",
    "#Training\n",
    "X_train_text,X_test_text,X_train_extra,X_test_extra,y_train,y_test=train_test_split(X_text,X_extra,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#TF-IDF\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,3),min_df=3,max_df=0.8,stop_words=\"english\",sublinear_tf=True,use_idf=True)\n",
    "\n",
    "#Fit on training data and transform both sets into numerical matrices\n",
    "X_train_tfidf=tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf=tfidf.transform(X_test_text)\n",
    "\n",
    "#Scaling numeric feature\n",
    "scaler=MinMaxScaler()\n",
    "X_train_extra_scaled=scaler.fit_transform(X_train_extra)\n",
    "X_test_extra_scaled=scaler.transform(X_test_extra)\n",
    "\n",
    "#Union+Emoji\n",
    "X_train_final=hstack([X_train_tfidf,X_train_extra_scaled])\n",
    "X_test_final=hstack([X_test_tfidf,X_test_extra_scaled])\n",
    "#Initializing and training Complement Naive Bayes Classifier\n",
    "model=ComplementNB(alpha=1)\n",
    "model.fit(X_train_final,y_train)\n",
    "\n",
    "#Model evaluation\n",
    "y_pred=model.predict(X_test_final)\n",
    "\n",
    "print(f\"Global Accuracy: {accuracy_score(y_test,y_pred):.2f}\\n\")\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
